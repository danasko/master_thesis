\chapter{Conclusion}\label{chap:conclusion}
% na uvod vseobecny blabol, ofc
In this thesis, the task of 3D human pose estimation from depth data is studied, while the core of the research is focused on the impact of a particular form of input data on the estimation accuracy and computational efficiency.\par
\vspace{5mm}
\noindent
As the main contribution of our work, we propose a novel two-stage deep learning method for an accurate single-person depth-based human pose estimation called Segmentation-Guided Pose Estimation. We eliminate drawbacks related to the projection of 3D space to a 2D image, when estimating pose from depth maps, by introducing a concept of unordered point clouds as a permutation-invariant input to a neural network. To allow the network to maintain both local and global contextual information, we employ intermediate concatenation of extracted pointwise and aggregated features inside the model. Additionally, we perform semantic segmentation of the input point cloud into the corresponding body regions, and utilize the per-point region assignment as an extend of the input point cloud before the final regression. Our proposed approach proved to benefit from the redundancy of the input to the segmentation and regression network, being able to absorb the local and global context at once.\par
\vspace{5mm}
\noindent
We believe engaging sparse point clouds as an input to the neural network instead of the commonly used depth maps allows us to provide a representation of the human body that is easier to be perceived by the network, while lowering memory requirements and computational cost at the same time. Moreover, to help preserve gradient flow throughout the entire depth of the network, we improved the shared multi-layer perceptron modules by additional skip-connections. Our strategy achieves competitive results on a number of benchmark datasets, and outperforms state-of-the-art approaches.\par
% TODO spomenut tu aj ze sme sa sustredili na metody priamo spracovavajuce point cloudy aj preto, ze planujeme vystup tejto prace aplikovat na data z 3D kamery Photoneo (zdroj), kt. produkuje point cloudy ?v realnom case? ale nasa metoda neni uplne real time tho. 
\vspace{5mm}
\noindent
Our interest to make use of the raw point clouds on the input, and focus on processing them directly, was aroused by the intention to apply the method proposed in this study on data obtained by the 3D MotionCam by Photoneo~\cite{photoneo}, which is currently the highest resolution and highest accuracy 3D camera in the world. The 3D camera produces a raw point cloud of the captured scene per frame. Thus, after being subsampled and normalized, the point cloud can be passed directly to our two-stage pose estimation pipeline.\par
% TODO dalsia dolezita cast naseho vyskumu spocivala v re-implementacii niekolkych z existujucich state-of-the-art metod, v nami zvolenom frameworku, mainly due to the absence of publicly released source code, and hence, the inability to reproduce the results, and apply the methods on different data.

\vspace{5mm}
\noindent
We consider an important part of this study to point out the most relevant limitations we encountered during the experiments. Regarding the depth-based human pose estimation, we see the biggest shortage in the range and accuracy of the available datasets. The suitable public datasets, containing both depth data of a captured human subject and the ground truth skeletal joint coordinates, are either too small to be used as training data for a neural network, or the accuracy of the ground truth labels is not sufficient. Moreover, even in large datasets, the data is often incomplete for certain sections, so the valid subset of the dataset ends up of a too small range after all. The limited accuracy of the ground truth poses is usually caused by poor synchronization of a depth sensor and a motion capture system. The most commonly used depth sensors do not have a stable frame rate, which results in time delays and misalignment between frames, and makes the precise synchronization practically impossible. In some of the datasets, this issue is partly fixed by time-stamping technique, refining the frame alignment, and filtering out the mismatches. It is even harder considering the multi-view approach, when the multiple depth sensors need to be synchronized mutually as well as with the motion capture system.\par
\vspace{5mm}
% TODO navrhnut nejaky direction of future research na zaver - nahratie rozsiahlejsieho datasetu (3d kamerou a optickym mocap systemom sucasne); pripadne pouzit synteticke data (ktore mozu byt vo velkom rozsahu generovane napr pomou SMPL modelu..) na augmentaciu realnych, co sa v doterajsich existujucich pokusoch/studiach ukazalo ako prospesne, vyuzitelne; dalej by sa dalo ako dalsie vylepsenie, extending the idea of processing raw point clouds - namiesto spracovavania celeho point cloudu naraz, s nim pracovat po castiach - clusteroch, nieco ako v modeli PointConv [citacia], kde sa jednotlive skupiny (mnoziny) bodov spracuvaju pomocou function of density and weight .. .
\noindent

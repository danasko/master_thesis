\chapter{Motivation}\label{chap:motivation}

The task of human pose estimation attracts a lot of attention among deep learning researchers, mainly because of its frequent usage in virtual and augmented reality, action recognition, surveillance, human-robot interaction, trajectory prediction or motion-based human identification. Although a lot has been achieved in the 3D human pose estimation task, there are still many challenges nowadays, which are not easy to overcome.\par
\vspace{5mm}
\noindent Since most of the research is currently focused on estimating the pose from RGB data, one of the most critical challenges of pose estimation from 3D input is data availability. To successfully train a neural network of reasonable size, a large and well labeled dataset is crucial. Right now, there is a very small set of publicly available 3D human pose estimation databases. Moreover, even among the available datasets, it is hard to find one that is both large enough in its scale, and accurate enough to avoid overfitting of the neural model. There are several large action recognition datasets with motion capture ground truth, but since providing the exact skeleton joint locations is not their primal purpose, the ground truth is often not accurate enough for the task of pose estimation.\par
\vspace{5mm}
\noindent Due to the lack of the accessible depth data, many researchers have recently used their own recorded depth datasets to evaluate the results of their proposed method. However, this leads to the fact, that it is difficult to objectively compare the particular methods to each other, because the recorded databases are often not published.
% tu pripadne dat, ze to je hlavny dovod, preco by sme chceli v ramci tejto prace nahrat a zverejnit ? vlastny depth dataset, a prispiet tak do komunity deep learning researcherov zoberajucich sa touto problematikou
It is important to mention, that recording of a quality depth dataset is not a trivial task, mainly since the expensive motion capture system is usually required to obtain accurate ground truth labels, which also limits us to indoor scenes. The usual workaround is to use the Kinect camera for recording, which can also directly extract the 3D skeleton joint coordinates, even though still working well only in indoor scenes.\par
\vspace{5mm}
\noindent Another issue concerning pose estimation from 3D data is the actual type of 3D data that is passed as input to the neural network. The most frequent option is to use depth maps, thus encoding the third dimension into the 2D image. Anyhow, the depth maps are a very dense representation of a 3D human pose. Also, a big part of the image space is representing the surrounding scene and background clutter, and the actual human body corresponds to a relatively small part of the scene. That results in expensive computations and lowering the time efficiency, while also processing the seemingly redundant data. On the other hand, in the attempt to overcome these drawbacks, voxelized grids have been used in several solutions to provide sparser 3D data representation as they only contain information about the scene near the shape of a desired subject. Voxelized grids are basically point clouds, discretized to the predefined grid values. However, voxels have their shortcomings too. One thing is that voxels require 3D convolution operations, which are rather demanding in terms of memory, time, and computing power. Moreover, the conversion of point clouds into the voxelized grids can be time-consuming itself.\par
\vspace{5mm}
\noindent The aim of our thesis is to develop a 3D human pose estimation pipeline based on neural network, which takes 3D data (in a form of a point cloud or a depth map) as input and outputs the 3D skeleton joint coordinates. % TODO upravit na striktne 3d data vo forme point cloudov ?
Our goal is to propose our own model, in addition to implementing several well-performing models proposed in existing papers. Next, we aim to evaluate them on %both existing 
benchmark datasets%, and our own novel recorded dataset
, and compare the results with the current state-of-the-art.\par